{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6da5c84",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0336cf",
   "metadata": {},
   "source": [
    "### LAB 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2748ec0",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d049e",
   "metadata": {},
   "source": [
    "## Neural Networks: Notes\n",
    "\n",
    "Neural networks are computational models inspired by the human brain. They consist of interconnected layers of nodes (neurons) that process data and learn complex patterns.\n",
    "\n",
    "### Key Concepts\n",
    "- **Neuron:** Basic unit that receives input, applies a function, and passes output.\n",
    "- **Layers:**\n",
    "  - **Input Layer:** Receives raw data.\n",
    "  - **Hidden Layers:** Intermediate layers that learn features.\n",
    "  - **Output Layer:** Produces final prediction.\n",
    "- **Weights & Biases:** Parameters learned during training.\n",
    "- **Activation Function:** Decides the output of a neuron given an input.\n",
    "\n",
    "---\n",
    "\n",
    "## Common Activation Functions\n",
    "\n",
    "### 1. ReLU (Rectified Linear Unit)\n",
    "- Formula: $f(x) = ax(0, x)$\n",
    "- Most popular for hidden layers.\n",
    "- Pros: Simple, helps with vanishing gradient.\n",
    "- Cons: Can die if too many outputs are zero.\n",
    "\n",
    "### 2. Sigmoid\n",
    "- Formula: $f(x) = \frac{1}{1 + e^{-x}}$\n",
    "- Output: (0, 1)\n",
    "- Used for binary classification.\n",
    "\n",
    "### 3. Tanh (Hyperbolic Tangent)\n",
    "- Formula: $f(x) = \tanh(x)$\n",
    "- Output: (-1, 1)\n",
    "- Zero-centered, often preferred over sigmoid.\n",
    "\n",
    "### 4. Softmax\n",
    "- Used in output layer for multi-class classification.\n",
    "- Converts logits to probabilities that sum to 1.\n",
    "\n",
    "### 5. Linear (Identity)\n",
    "- Formula: $f(x) = x$\n",
    "- Used in output layer for regression tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Table:**\n",
    "\n",
    "| Function  | Formula                | Output Range | Use Case                  |\n",
    "|-----------|------------------------|--------------|---------------------------|\n",
    "| ReLU      | $ax(0, x)$           | [0, ∞)       | Hidden layers             |\n",
    "| Sigmoid   | $\frac{1}{1+e^{-x}}$   | (0, 1)       | Binary classification     |\n",
    "| Tanh      | $\tanh(x)$             | (-1, 1)      | Hidden layers             |\n",
    "| Softmax   | $\frac{e^{x_i}}{um e^{x_j}}$ | (0, 1) | Multi-class classification|\n",
    "| Linear    | $x$                    | (-∞, ∞)      | Regression output         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39d770",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "### Types of Neural Networks\n",
    "- **ANN (Artificial Neural Network):**\n",
    "  - Basic neural network with input, hidden, and output layers. Used for tabular data, regression, and classification.\n",
    "- **CNN (Convolutional Neural Network):**\n",
    "  - Specialized for image and spatial data. Uses convolutional layers to extract features.\n",
    "- **R-CNN (Region-based CNN):**\n",
    "  - Used for object detection in images. Proposes regions and classifies them. Variants include Fast R-CNN, Faster R-CNN, and Mask R-CNN (adds segmentation).\n",
    "- **YOLO (You Only Look Once):**\n",
    "  - Real-time object detection system. Processes the entire image in one pass for fast detection.\n",
    "- **Deep Learning:**\n",
    "  - General term for neural networks with many layers (deep architectures). Enables learning of complex patterns.\n",
    "- **Transformers:**\n",
    "  - Sequence models using self-attention. State-of-the-art for NLP tasks (e.g., BERT, GPT).\n",
    "- **ViT (Vision Transformer):**\n",
    "  - Applies transformer architecture to image data. Splits images into patches and processes them like sequences.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac8fd7",
   "metadata": {},
   "source": [
    "# CNN Coding Pathway: Step-by-Step Guide\n",
    "This section outlines the typical steps to build a Convolutional Neural Network (CNN) for image classification, with explanations and diagrams where helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ffba9",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "Import essential libraries for data handling, visualization, and deep learning (e.g., TensorFlow/Keras, NumPy, Matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79adfde0",
   "metadata": {},
   "source": [
    "## 2. Importing Data\n",
    "Load your image dataset. Data is often organized in folders by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a569af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load images from directory\n",
    "train_dir = 'path/to/train'\n",
    "val_dir = 'path/to/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc1fd1",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "### a. Training/Validation Split\n",
    "Split your data into training and validation sets to evaluate model performance.\n",
    "\n",
    "### b. Image Augmentation\n",
    "Augmentation artificially increases dataset size and diversity.\n",
    "- **Flip:** Randomly flip images horizontally/vertically.\n",
    "- **Rotate:** Randomly rotate images.\n",
    "- **Shear:** Apply shearing transformations.\n",
    "- **Zoom:** Randomly zoom in/out.\n",
    "- **Normalize:** Scale pixel values (e.g., to [0,1]).\n",
    "\n",
    "**Diagram: Image Augmentation**\n",
    "\n",
    "![Augmentation](https://raw.githubusercontent.com/keras-team/keras-io/master/img/data_augmentation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b3ff3",
   "metadata": {},
   "source": [
    "## 4. Build the CNN Model\n",
    "A typical CNN has convolutional layers (for feature extraction), pooling layers (for downsampling), and dense layers (for classification).\n",
    "\n",
    "**Diagram: CNN Architecture**\n",
    "\n",
    "![CNN Diagram](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5598481",
   "metadata": {},
   "source": [
    "## 5. Compile and Train the Model\n",
    "- **Compile:** Set optimizer, loss function, and metrics.\n",
    "- **Train:** Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617cceb",
   "metadata": {},
   "source": [
    "## 6. Evaluate and Predict\n",
    "- **Evaluation:** Assess model performance on validation/test data.\n",
    "- **Prediction:** Use the trained model to predict new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd64d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "val_loss, val_acc = model.evaluate(validation_generator)\n",
    "print(f'Validation accuracy: {val_acc:.2f}')\n",
    "\n",
    "# Predict\n",
    "img = tf.keras.utils.load_img('path/to/image.jpg', target_size=(150, 150))\n",
    "img_array = tf.keras.utils.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f'Predicted class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2afafe",
   "metadata": {},
   "source": [
    "## Key CNN Training Concepts Explained\n",
    "- - -\n",
    "- **Epoch:** One complete pass through the entire training dataset. More epochs allow the model to learn better, but too many can cause overfitting.\n",
    "\n",
    "- **Batch Size:** Number of samples processed before the model updates its weights. Smaller batches use less memory but may be slower.\n",
    "\n",
    "- **Steps per Epoch:** Number of batches processed in one epoch. For generators, it's usually `total_samples // batch_size`.\n",
    "\n",
    "- **Learning Rate:** Controls how much the model weights are updated during training. Too high can cause instability, too low can slow learning.\n",
    "\n",
    "- **Optimizer:** Algorithm that updates weights to minimize loss (e.g., Adam, SGD).\n",
    "\n",
    "- **Loss Function:** Measures how well the model predicts the target. For \n",
    "classification, use `categorical_crossentropy`.\n",
    "\n",
    "- **Metrics:** Quantities to monitor during training (e.g., accuracy).\n",
    "\n",
    "- **Overfitting:** When a model learns the training data too well, including noise, and performs poorly on new data.\n",
    "\n",
    "- **Validation Data:** Data not seen by the model during training, used to check generalization.\n",
    "\n",
    "**Tip:** Use early stopping or dropout layers to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754eba79",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8744e5",
   "metadata": {},
   "source": [
    "# CAT DOG - CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1e2ec",
   "metadata": {},
   "source": [
    "### BINARY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38943be2",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19cd691",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
